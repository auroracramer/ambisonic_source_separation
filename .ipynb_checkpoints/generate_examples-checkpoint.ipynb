{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import random\n",
    "import math\n",
    "from scipy.io import loadmat\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srir_path = '/beegfs/jtc440/3daudio/Tietotalo_RIR.mat'\n",
    "noise_dir = '/beegfs/jtc440/3daudio/datasets/noise/freesound'\n",
    "speech_dir = '/beegfs/jtc440/3daudio/datasets/speech/vctk/VCTK-Corpus/wav48'\n",
    "diffuse_dir = '/beegfs/jtc440/3daudio/atk/kernels/FOA/encoders/diffuse/None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick a random speaker and a random example\n",
    "speaker_dir = os.path.join(speech_dir, random.choice(os.listdir(speech_dir)))\n",
    "speech_path = os.path.join(speaker_dir, random.choice(os.listdir(speaker_dir)))\n",
    "src_audio, sr = librosa.load(speech_path, sr=44100, mono=True)\n",
    "src_audio /= src_audio.max()\n",
    "\n",
    "# Randomly sample noise\n",
    "fname = random.choice(os.listdir(noise_dir))\n",
    "noise_path = os.path.join(noise_dir, fname)\n",
    "noise_data = None\n",
    "\n",
    "# Make sure we have more noise than source\n",
    "while noise_data is None or noise_data.shape[0] < src_audio.shape[0]:\n",
    "    noise_data, sr = librosa.load(noise_path, sr=44100, mono=True)\n",
    "noise_data /= noise_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip noise audio to be same length\n",
    "clip_len = src_audio.shape[0]\n",
    "start_idx = np.random.randint(0, noise_data.shape[0] - clip_len)\n",
    "noise_data = noise_data[start_idx:start_idx + clip_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snr = 10 * np.log10(np.mean(src_audio ** 2) / np.mean(noise_data ** 2))\n",
    "\n",
    "# Sample an SNR [-20, 20] (subject to change)\n",
    "snr_target = np.random.random() * 40.0 - 20.0\n",
    "\n",
    "# Compute scaling factor for speech -> this assumes energy is preserved when going to B-format and applying SRIRs\n",
    "alpha = 10.0**((snr_target - snr) / 20.0)\n",
    "\n",
    "src_audio *= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snr_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Block size: 512, 1024, 2048, 4096, 8192, 16384\n",
    "# Phase diffusion: 0, 1, 2, 3, 4, 5\n",
    "def get_diffuse_ir(block_size, phase_diffusion):\n",
    "    return os.path.join(diffuse_dir, str(block_size), \"%0.4d\" % phase_diffusion, \"diffuse.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_size = random.choice([512, 1024, 2048, 4096, 8192, 16384])\n",
    "phase_diffusion = np.random.randint(0, 6)\n",
    "diffuse_ir_path = get_diffuse_ir(kernel_size, phase_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Channels: W X Y Z\n",
    "diffuse_ir, sr = librosa.load(diffuse_ir_path, sr=44100, mono=False)\n",
    "\n",
    "# Scale by twice the kernel size, as in the original code\n",
    "diffuse_ir /= 2 * kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffuse_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sh_names = [\"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "ch_out_list = []\n",
    "\n",
    "for idx, sh_str in enumerate(sh_names):\n",
    "    ch_ir = diffuse_ir[idx]\n",
    "    \n",
    "    ch_ir_len = ch_ir.shape[0]\n",
    "    noise_len = noise_data.shape[0]\n",
    "    \n",
    "    if ch_ir_len > noise_len:\n",
    "        pad_len = ch_ir_len - noise_len\n",
    "        noise_data = np.pad(noise_data, (0, pad_len), mode='constant')\n",
    "    elif ch_ir_len < noise_len:\n",
    "        pad_len = noise_len - ch_ir_len\n",
    "        ch_ir = np.pad(ch_ir, (0, pad_len), mode='constant')\n",
    "        \n",
    "    ch_out = scipy.signal.fftconvolve(noise_data, ch_ir, mode='full')[:noise_len]\n",
    "    ch_out_list.append(ch_out)\n",
    "    \n",
    "noise_bformat = np.array(ch_out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenmike processing\n",
    "\n",
    "Incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noise_ch_out = []\n",
    "# for diffuse_ir_ch in diffuse_ir:\n",
    "#     pad_len = noise_data.shape[0] - diffuse_ir_ch.shape[0]\n",
    "#     diffuse_ir_ch_pad = np.pad(diffuse_ir_ch, (0, pad_len), mode='constant')\n",
    "#     noise_ch = scipy.signal.fftconvolve(noise_data, diffuse_ir_ch_pad, mode=\"full\")\n",
    "#     noise_ch_out.append(noise_ch)\n",
    "    \n",
    "# noise_ch_out = np.array(noise_ch_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size: (2, 9, 1025, 36, 4, 32) = (distance_wrt_mic, elevation_wrt_mic, FFT,  azimuth_wrt_mic, blocks, channels).\n",
    "\n",
    "where,\n",
    "\n",
    "distance_wrt_mic = two distances (1m and 2m)\n",
    "elevation_wrt_mic = 9 elevation angles (-40:10:40) at distance 1m, and 5 elevations angles (-20:10:20) at distance 2m.\n",
    "azimuth_wrt_mic = 36 azimuth angles (-180:10:180) for all distance-elevation combination\n",
    "The IRs were extracted assuming block-wise stationarity (four blocks) for each frequency bin (1025 bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# azimuth_to_idx = {x: idx for idx, x in enumerate(np.arange(-180, 180, 10))}\n",
    "# elevation_to_idx = {x: idx for idx, x in enumerate(np.arange(-40, 40, 10))}\n",
    "\n",
    "# distance_to_idx = {1: 0, 2: 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# srir = loadmat(srir_path)\n",
    "# srir = srir['rir_DB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Convert FFT to IR\n",
    "# srir = np.fft.irfft(srir, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# azi = azimuth_to_idx[40]\n",
    "# elv = elevation_to_idx[20]\n",
    "# dst = distance_to_idx[1]\n",
    "\n",
    "# chosen_srir = srir[dst, elv, :, azi, 0, :]\n",
    "# ch_out_list = []\n",
    "# num_channels = srir.shape[-1]\n",
    "# for channel in range(num_channels):\n",
    "#     # Get corresponding impulse response\n",
    "#     ch_srir = chosen_srir[:, channel]\n",
    "#     pad = audio.shape[0] - len(ch_srir)\n",
    "    \n",
    "#     # Pad impulse responses for convolution.\n",
    "#     ch_srir_pad = np.pad(ch_srir, (0, pad), mode='constant')\n",
    "    \n",
    "#     # Perform convolution\n",
    "#     ch_out = scipy.signal.fftconvolve(audio[:, idx], ch_srir_pad, mode='full')\n",
    "    \n",
    "#     # Only take samples corresponding to original audio\n",
    "#     ch_out = ch_out[:audio.shape[0]]\n",
    "#     ch_out_list.append(ch_out)\n",
    "    \n",
    "# src_eigen = np.array(ch_out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isophonics processing\n",
    "\n",
    "isophonics.net/content/room-impulse-response-data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that we swap x and y here to be consistent with standard \n",
    "# spherical coordinate convention\n",
    "speaker_coord = np.array([-2, 6, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian_to_spherical(dist_coord, rads=True):\n",
    "    # Convert cartesian coordiantes to spherical coordinates\n",
    "    x, y, z = dist_coord\n",
    "    r = np.linalg.norm(dist_coord)\n",
    "    azi = math.atan2(y, x)\n",
    "    elv = math.acos(z/float(r))\n",
    "    \n",
    "    if not rads:\n",
    "        azi = azi * 180.0 / np.pi\n",
    "        elv = elv * 180.0 / np.pi\n",
    "        \n",
    "    return np.array([r, azi, elv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/polarch/Spherical-Harmonic-Transform/blob/master/euler2rotationMatrix.m\n",
    "def euler_to_rotation_matrix(alpha, beta, gamma, order='xyz'):\n",
    "    \"\"\"\n",
    "    %   alpha:  first angle of rotation\n",
    "    %   beta:   second angle of rotation\n",
    "    %   gamma:  third angle of rotation\n",
    "    %\n",
    "    %   order:  definition of the axes of rotation, e.g. for the y-convention\n",
    "    %           this should be 'zyz', for the x-convnention 'zxz', and for\n",
    "    %           the yaw-pitch-roll convention 'zyx'\n",
    "    \"\"\"\n",
    "    def Rx(theta):\n",
    "        return np.array([\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, np.cos(theta), np.sin(theta)],\n",
    "            [0.0, -np.sin(theta), np.cos(theta)]])\n",
    "    \n",
    "    def Ry(theta):\n",
    "        return np.array([\n",
    "            [np.cos(theta), 0.0, -np.sin(theta)],\n",
    "            [0.0, 1.0, 0.0],\n",
    "            [np.sin(theta), 0.0, np.cos(theta)]\n",
    "        ])\n",
    "    # [cos(theta) sin(theta) 0; -sin(theta) cos(theta) 0; 0 0 1]\n",
    "    def Rz(theta):\n",
    "        return np.array([\n",
    "            [np.cos(theta), np.sin(theta), 0.0],\n",
    "            [-np.sin(theta), np.cos(theta), 0.0],\n",
    "            [0.0, 0.0, 1.0]])\n",
    "    \n",
    "    R = np.eye(3)\n",
    "    for idx, dim in reversed(list(enumerate(order))):\n",
    "        if dim == 'x':\n",
    "            R_func = Rx\n",
    "        elif dim == 'y':\n",
    "            R_func = Ry\n",
    "        elif dim == 'z':\n",
    "            R_func = Rz\n",
    "            \n",
    "        if idx == 0:\n",
    "            theta = alpha\n",
    "        elif idx == 1:\n",
    "            theta = beta\n",
    "        elif idx == 2:\n",
    "            theta = gamma\n",
    "            \n",
    "        R = np.dot(R, R_func(theta))\n",
    "        \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/polarch/Higher-Order-Ambisonics/blob/master/rotateBformat.m\n",
    "def rotate_bformat(bfsig, yaw, pitch, roll, order='xyz'):\n",
    "    R_mat = euler_to_rotation_matrix(-yaw*np.pi/180.0,\n",
    "                                     -pitch*np.pi/180.0,\n",
    "                                     roll*np.pi/180,\n",
    "                                     order=order);\n",
    "\n",
    "    # augment with zero order\n",
    "    Rbf = np.zeros((4,4));\n",
    "    Rbf[0,:] = 1.0;\n",
    "    Rbf[1:,1:] = R_mat;\n",
    "\n",
    "    # apply to B-format signals\n",
    "    return np.dot(Rbf, bfsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_coord(coord, yaw, pitch, roll, order='xyz'):\n",
    "    R_mat = euler_to_rotation_matrix(-yaw*np.pi/180.0,\n",
    "                                     -pitch*np.pi/180.0,\n",
    "                                     roll*np.pi/180,\n",
    "                                     order=order);\n",
    "\n",
    "    return np.dot(R_mat, coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srir_dir = '/beegfs/jtc440/3daudio/srir/isophonics/greathall'\n",
    "\n",
    "# Sample a grid position\n",
    "grid_x = np.random.randint(0, 13)\n",
    "grid_y = np.random.randint(0, 13)\n",
    "\n",
    "# Note that we swap x and y here to be consistent with standard \n",
    "# spherical coordinate convention\n",
    "x = grid_y\n",
    "y = grid_x\n",
    "\n",
    "mic_coord = np.array([x, y, 0])\n",
    "rel_src_coord = mic_coord - speaker_coord\n",
    "\n",
    "ch_out_list = []\n",
    "\n",
    "sh_names = [\"W\", \"X\", \"Y\", \"Z\"]\n",
    "for sh_str in sh_names:\n",
    "    ch_ir_path = os.path.join(srir_dir, sh_str,\n",
    "                              \"{}x{:02d}y{:02d}.wav\".format(sh_str, grid_x, grid_y))\n",
    "    ch_ir, sr = librosa.load(ch_ir_path, sr=44100)\n",
    "    \n",
    "    ch_ir_len = ch_ir.shape[0]\n",
    "    src_len = src_audio.shape[0]\n",
    "    \n",
    "    if ch_ir_len > src_len:\n",
    "        pad_len = ch_ir_len - src_len\n",
    "        src_audio = np.pad(src_audio, (0, pad_len), mode='constant')\n",
    "    elif ch_ir_len < src_len:\n",
    "        pad_len = src_len - ch_ir_len\n",
    "        ch_ir = np.pad(ch_ir, (0, pad_len), mode='constant')\n",
    "        \n",
    "    ch_out = scipy.signal.fftconvolve(src_audio, ch_ir, mode='full')[:src_len]\n",
    "    ch_out_list.append(ch_out)\n",
    "\n",
    "src_bformat = np.array(ch_out_list)\n",
    "\n",
    "\n",
    "# Rotate perspective to get more positions, since we don't have source from all around\n",
    "# Randomly sample yaw-pitch-roll\n",
    "d_yaw = (2*np.random.random() - 1) * 180.0\n",
    "d_pitch = (2*np.random.random() - 1) * 90.0\n",
    "d_roll = (2*np.random.random() -1) * 90.0\n",
    "\n",
    "rot_src_bformat = rotate_bformat(src_bformat, d_yaw, d_pitch, d_roll, order='xyz')\n",
    "rot_src_coord = rotate_coord(rel_src_coord, d_yaw, d_pitch, d_roll, order='xyz')\n",
    "rot_src_coord_spherical = cartesian_to_spherical(rot_src_coord, rads=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_90(audio):\n",
    "    return scipy.signal.hilbert(audio).imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix signal and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Find out a way to compute SNR in B-format\n",
    "mix_bformat = rot_src_bformat + noise_bformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mix to stereo according to https://en.wikipedia.org/wiki/Ambisonic_UHJ_format#UHJ_encoding_and_decoding_equations\n",
    "# S = 0.9396926*W + 0.1855740*X\n",
    "# D = j(-0.3420201*W + 0.5098604*X) + 0.6554516*Y\n",
    "# Left = (S + D)/2.0\n",
    "# Right = (S - D)/2.0\n",
    "S = 0.9396926 * mix_bformat[0] + 0.1855740 * mix_bformat[1]\n",
    "D = rotate_90(-0.3420201 * mix_bformat[0] + 0.5098604 * mix_bformat[1]) + 0.6554516 * mix_bformat[2]\n",
    "L = (S + D)/2.0\n",
    "R = (S - D)/2.0\n",
    "mix_mono = S\n",
    "mix_stereo = np.stack([L,R])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(data=src_audio, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(data=noise_data, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated mix (mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(data=mix_mono, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated mix (stereo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(data=mix_stereo, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
